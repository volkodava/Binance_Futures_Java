{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/volkodava/Binance_Futures_Java/blob/master/notebooks/how-to-use-ultralytics-yolo-with-sahi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6MPjfT5NrKQ"
      },
      "source": [
        "<div align=\"center\">\n",
        "\n",
        "  <a href=\"https://ultralytics.com/yolo\" target=\"_blank\">\n",
        "    <img width=\"1024\", src=\"https://raw.githubusercontent.com/ultralytics/assets/main/yolov8/banner-yolov8.png\"></a>\n",
        "\n",
        "  [‰∏≠Êñá](https://docs.ultralytics.com/zh/) | [ÌïúÍµ≠Ïñ¥](https://docs.ultralytics.com/ko/) | [Êó•Êú¨Ë™û](https://docs.ultralytics.com/ja/) | [–†—É—Å—Å–∫–∏–π](https://docs.ultralytics.com/ru/) | [Deutsch](https://docs.ultralytics.com/de/) | [Fran√ßais](https://docs.ultralytics.com/fr/) | [Espa√±ol](https://docs.ultralytics.com/es/) | [Portugu√™s](https://docs.ultralytics.com/pt/) | [T√ºrk√ße](https://docs.ultralytics.com/tr/) | [Ti·∫øng Vi·ªát](https://docs.ultralytics.com/vi/) | [ÿßŸÑÿπÿ±ÿ®Ÿäÿ©](https://docs.ultralytics.com/ar/)\n",
        "\n",
        "  <a href=\"https://github.com/ultralytics/ultralytics/actions/workflows/ci.yml\"><img src=\"https://github.com/ultralytics/ultralytics/actions/workflows/ci.yml/badge.svg\" alt=\"Ultralytics CI\"></a>\n",
        "  <a href=\"https://colab.research.google.com/github/ultralytics/notebooks/blob/main/notebooks/how-to-use-ultralytics-yolo-with-sahi.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"></a>\n",
        "\n",
        "  <a href=\"https://ultralytics.com/discord\"><img alt=\"Discord\" src=\"https://img.shields.io/discord/1089800235347353640?logo=discord&logoColor=white&label=Discord&color=blue\"></a>\n",
        "  <a href=\"https://community.ultralytics.com\"><img alt=\"Ultralytics Forums\" src=\"https://img.shields.io/discourse/users?server=https%3A%2F%2Fcommunity.ultralytics.com&logo=discourse&label=Forums&color=blue\"></a>\n",
        "  <a href=\"https://reddit.com/r/ultralytics\"><img alt=\"Ultralytics Reddit\" src=\"https://img.shields.io/reddit/subreddit-subscribers/ultralytics?style=flat&logo=reddit&logoColor=white&label=Reddit&color=blue\"></a>\n",
        "  \n",
        "  Welcome to the <a href=\"https://docs.ultralytics.com/guides/sahi-tiled-inference/\">Ultralytics YOLO11 with SAHI notebook üöÄ</a>. YOLO11 is the latest version of the YOLO (You Only Look Once) AI models developed by <a href=\"https://ultralytics.com\">Ultralytics</a>. We hope that the resources in this notebook will help you get the most out of YOLO11 usage with SAHI. Please browse the YOLO11 <a href=\"https://docs.ultralytics.com/\">Docs</a> for details, raise an issue on <a href=\"https://github.com/ultralytics/ultralytics\">GitHub</a> for support, and join our <a href=\"https://ultralytics.com/discord\">Discord</a> community for questions and discussions!</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ultralytics YOLO11 with SAHI\n",
        "\n",
        "This notebook serves as the starting point for using the YOLO11 model with [SAHI (Slicing Aided Hyper Inference)](https://docs.ultralytics.com/guides/sahi-tiled-inference/).\n",
        "\n",
        "### What is Sliced Inference?\n",
        "\n",
        "Sliced Inference refers to the practice of subdividing a large or high-resolution image into smaller segments (slices), conducting object detection on these slices, and then recompiling the slices to reconstruct the object locations on the original image. This technique is invaluable in scenarios where computational resources are limited or when working with extremely high-resolution images that could otherwise lead to memory issues.\n",
        "\n",
        "### Benefits of Sliced Inference\n",
        "\n",
        "- **Reduced Computational Burden**: Smaller image slices are faster to process, and they consume less memory, enabling smoother operation on lower-end hardware.\n",
        "\n",
        "- **Preserved Detection Quality**: Since each slice is treated independently, there is no reduction in the quality of object detection, provided the slices are large enough to capture the objects of interest.\n",
        "\n",
        "- **Enhanced Scalability**: The technique allows for object detection to be more easily scaled across different sizes and resolutions of images, making it ideal for a wide range of applications from satellite imagery to medical diagnostics."
      ],
      "metadata": {
        "id": "7EM2nwU4jshF"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mGmQbAO5pQb"
      },
      "source": [
        "### Setup\n",
        "\n",
        "pip install `ultralytics` and [dependencies](https://github.com/ultralytics/ultralytics/blob/main/pyproject.toml) and check software and hardware.\n",
        "\n",
        "[![PyPI - Version](https://img.shields.io/pypi/v/ultralytics?logo=pypi&logoColor=white)](https://pypi.org/project/ultralytics/) [![Downloads](https://static.pepy.tech/badge/ultralytics)](https://www.pepy.tech/projects/ultralytics) [![PyPI - Python Version](https://img.shields.io/pypi/pyversions/ultralytics?logo=python&logoColor=gold)](https://pypi.org/project/ultralytics/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbvMlHd_QwMG",
        "outputId": "ad3533f2-d8ee-4c5c-fe45-203fa8ce2d7e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install ultralytics sahi\n",
        "import ultralytics\n",
        "from ultralytics.utils.downloads import safe_download\n",
        "ultralytics.checks()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.144 üöÄ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Setup complete ‚úÖ (2 CPUs, 12.7 GB RAM, 41.5/112.6 GB disk)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Clone Repository\n",
        "\n",
        "- Clone the `ultralytics` repository.\n",
        "- `%cd` to the examples section.\n",
        "- Move to `YOLOv8-SAHI-Inference-Video` folder."
      ],
      "metadata": {
        "id": "I7XY-vtnkPYf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone ultralytics repo\n",
        "!git clone https://github.com/ultralytics/ultralytics\n",
        "\n",
        "# cd to local directory\n",
        "%cd ultralytics/examples/YOLOv8-SAHI-Inference-Video"
      ],
      "metadata": {
        "id": "fNX-Ymha0HY6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5a69c8a-dee9-4e39-c9c9-fa96d89b2b32"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ultralytics'...\n",
            "remote: Enumerating objects: 60469, done.\u001b[K\n",
            "remote: Counting objects: 100% (53/53), done.\u001b[K\n",
            "remote: Compressing objects: 100% (32/32), done.\u001b[K\n",
            "remote: Total 60469 (delta 33), reused 32 (delta 21), pack-reused 60416 (from 2)\u001b[K\n",
            "Receiving objects: 100% (60469/60469), 32.80 MiB | 22.11 MiB/s, done.\n",
            "Resolving deltas: 100% (44943/44943), done.\n",
            "/content/ultralytics/examples/YOLOv8-SAHI-Inference-Video\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download the Sample Video\n",
        "\n",
        "- If you want to use your own video, you can skip this step."
      ],
      "metadata": {
        "id": "mWszyoifxOtR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "safe_download(f\"https://github.com/ultralytics/assets/releases/download/v0.0.0/sahi.demo.video.mp4\", dir=\"/content\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kkef3pklxVKP",
        "outputId": "560b2980-c3c6-45b1-e224-33e0b0ebdd77"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://ultralytics.com/assets/sahi.demo.video.mp4 to '/content/sahi.demo.video.mp4'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15.3M/15.3M [00:00<00:00, 105MB/s] \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PosixPath('/content/sahi.demo.video.mp4')"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inference using SAHI\n",
        "\n",
        "The output results will be stored in `ultralytics/ultralytics/examples/YOLOv8-SAHI-Inference-Video/`"
      ],
      "metadata": {
        "id": "yoP5eiVX1X37"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#inference (default latest model will be selected i.e yolo11n.pt)\n",
        "!python yolov8_sahi.py --source \"/content/sahi.demo.video.mp4\""
      ],
      "metadata": {
        "id": "B1YbLnvG1WAS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79d34e39-d96f-47bf-c10b-b4bed437526a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\ryolo11n.pt:   0% 0.00/5.35M [00:00<?, ?B/s]\ryolo11n.pt: 100% 5.35M/5.35M [00:00<00:00, 86.4MB/s]\n",
            "Ultralytics 8.3.144 üöÄ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'models/yolo11n.pt'...\n",
            "100% 5.35M/5.35M [00:00<00:00, 110MB/s]\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the original script\n",
        "with open('/content/ultralytics/examples/YOLOv8-SAHI-Inference-Video/yolov8_sahi.py', 'r') as f:\n",
        "    content = f.read()\n",
        "\n",
        "# Replace the problematic line\n",
        "content = content.replace(\n",
        "    'download_model_weights(yolo11_model_path)  # Download model if not present',\n",
        "    '# download_model_weights(yolo11_model_path)  # Commented out for YOLOv11 support'\n",
        ")\n",
        "\n",
        "# Write the modified script back\n",
        "with open('/content/ultralytics/examples/YOLOv8-SAHI-Inference-Video/yolov8_sahi.py', 'w') as f:\n",
        "    f.write(content)\n",
        "\n",
        "print(\"Script patched successfully!\")"
      ],
      "metadata": {
        "id": "P9R8a6W_uEgP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "37af7d4d-7c49-4e8e-c7fe-2c112f6583db"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Script patched successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/ultralytics/examples/YOLOv8-SAHI-Inference-Video/yolov8_sahi.py --source \"/content/sahi.demo.video.mp4\" --weights \"yolo11s.pt\" --save-img\n"
      ],
      "metadata": {
        "id": "fvnaNgi8dZ_J",
        "outputId": "2a0c09a3-17a7-42cc-da64-d6aa3848b881",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.144 üöÄ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11s.pt to 'models/yolo11s.pt'...\n",
            "100% 18.4M/18.4M [00:00<00:00, 155MB/s]\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Performing prediction on 9 slices.\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/ultralytics/examples/YOLOv8-SAHI-Inference-Video/yolov8_sahi.py\", line 147, in <module>\n",
            "    inference.inference(**vars(inference.parse_opt()))\n",
            "  File \"/content/ultralytics/examples/YOLOv8-SAHI-Inference-Video/yolov8_sahi.py\", line 100, in inference\n",
            "    results = get_sliced_prediction(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sahi/predict.py\", line 281, in get_sliced_prediction\n",
            "    prediction_result = get_prediction(\n",
            "                        ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sahi/predict.py\", line 109, in get_prediction\n",
            "    image_as_pil = read_image_as_pil(image)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sahi/utils/cv.py\", line 234, in read_image_as_pil\n",
            "    image_pil = Image.fromarray(image)\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/PIL/Image.py\", line 3319, in fromarray\n",
            "    obj = obj.tobytes()\n",
            "          ^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cat /content/ultralytics/examples/YOLOv8-SAHI-Inference-Video/yolov8_sahi.py"
      ],
      "metadata": {
        "id": "xa2Pn_eEdiaG",
        "outputId": "7bff983c-07da-4b0f-abfe-7e4985741d0f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# Ultralytics üöÄ AGPL-3.0 License - https://ultralytics.com/license\n",
            "\n",
            "import argparse\n",
            "\n",
            "import cv2\n",
            "from sahi import AutoDetectionModel\n",
            "from sahi.predict import get_sliced_prediction\n",
            "from sahi.utils.ultralytics import download_model_weights\n",
            "\n",
            "from ultralytics.utils.files import increment_path\n",
            "\n",
            "\n",
            "class SAHIInference:\n",
            "    \"\"\"\n",
            "    Runs Ultralytics YOLO11 and SAHI for object detection on video with options to view, save, and track results.\n",
            "\n",
            "    This class integrates SAHI (Slicing Aided Hyper Inference) with YOLO11 models to perform efficient object detection\n",
            "    on large images by slicing them into smaller pieces, running inference on each slice, and then merging the results.\n",
            "\n",
            "    Attributes:\n",
            "        detection_model (AutoDetectionModel): The loaded YOLO11 model wrapped with SAHI functionality.\n",
            "\n",
            "    Methods:\n",
            "        load_model: Load a YOLO11 model with specified weights for object detection using SAHI.\n",
            "        inference: Run object detection on a video using YOLO11 and SAHI.\n",
            "        parse_opt: Parse command line arguments for the inference process.\n",
            "\n",
            "    Examples:\n",
            "        Initialize and run SAHI inference on a video\n",
            "        >>> sahi_inference = SAHIInference()\n",
            "        >>> sahi_inference.inference(weights=\"yolo11n.pt\", source=\"video.mp4\", view_img=True)\n",
            "    \"\"\"\n",
            "\n",
            "    def __init__(self):\n",
            "        \"\"\"Initialize the SAHIInference class for performing sliced inference using SAHI with YOLO11 models.\"\"\"\n",
            "        self.detection_model = None\n",
            "\n",
            "    def load_model(self, weights: str, device: str) -> None:\n",
            "        \"\"\"\n",
            "        Load a YOLO11 model with specified weights for object detection using SAHI.\n",
            "\n",
            "        Args:\n",
            "            weights (str): Path to the model weights file.\n",
            "            device (str): CUDA device, i.e., '0' or '0,1,2,3' or 'cpu'.\n",
            "        \"\"\"\n",
            "        from ultralytics.utils.torch_utils import select_device\n",
            "\n",
            "        yolo11_model_path = f\"models/{weights}\"\n",
            "        download_model_weights(yolo11_model_path)  # Download model if not present\n",
            "        self.detection_model = AutoDetectionModel.from_pretrained(\n",
            "            model_type=\"ultralytics\", model_path=yolo11_model_path, device=select_device(device)\n",
            "        )\n",
            "\n",
            "    def inference(\n",
            "        self,\n",
            "        weights: str = \"yolo11n.pt\",\n",
            "        source: str = \"test.mp4\",\n",
            "        view_img: bool = False,\n",
            "        save_img: bool = False,\n",
            "        exist_ok: bool = False,\n",
            "        device: str = \"\",\n",
            "        hide_conf: bool = False,\n",
            "        slice_width: int = 512,\n",
            "        slice_height: int = 512,\n",
            "    ) -> None:\n",
            "        \"\"\"\n",
            "        Run object detection on a video using YOLO11 and SAHI.\n",
            "\n",
            "        The function processes each frame of the video, applies sliced inference using SAHI,\n",
            "        and optionally displays and/or saves the results with bounding boxes and labels.\n",
            "\n",
            "        Args:\n",
            "            weights (str): Model weights' path.\n",
            "            source (str): Video file path.\n",
            "            view_img (bool): Whether to display results in a window.\n",
            "            save_img (bool): Whether to save results to a video file.\n",
            "            exist_ok (bool): Whether to overwrite existing output files.\n",
            "            device (str, optional): CUDA device, i.e., '0' or '0,1,2,3' or 'cpu'.\n",
            "            hide_conf (bool, optional): Flag to show or hide confidences in the output.\n",
            "            slice_width (int, optional): Slice width for inference.\n",
            "            slice_height (int, optional): Slice height for inference.\n",
            "        \"\"\"\n",
            "        # Video setup\n",
            "        cap = cv2.VideoCapture(source)\n",
            "        assert cap.isOpened(), \"Error reading video file\"\n",
            "\n",
            "        # Output setup\n",
            "        save_dir = increment_path(\"runs/detect/predict\", exist_ok)\n",
            "        save_dir.mkdir(parents=True, exist_ok=True)\n",
            "\n",
            "        # Load model\n",
            "        self.load_model(weights, device)\n",
            "        idx = 0  # Index for image frame writing\n",
            "        while cap.isOpened():\n",
            "            success, frame = cap.read()\n",
            "            if not success:\n",
            "                break\n",
            "\n",
            "            # Perform sliced prediction using SAHI\n",
            "            results = get_sliced_prediction(\n",
            "                frame[..., ::-1],  # Convert BGR to RGB\n",
            "                self.detection_model,\n",
            "                slice_height=slice_height,\n",
            "                slice_width=slice_width,\n",
            "            )\n",
            "\n",
            "            # Display results if requested\n",
            "            if view_img:\n",
            "                cv2.imshow(\"Ultralytics YOLO Inference\", frame)\n",
            "\n",
            "            # Save results if requested\n",
            "            if save_img:\n",
            "                idx += 1\n",
            "                results.export_visuals(export_dir=save_dir, file_name=f\"img_{idx}\", hide_conf=hide_conf)\n",
            "\n",
            "            # Break loop if 'q' is pressed\n",
            "            if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
            "                break\n",
            "\n",
            "        # Clean up resources\n",
            "        cap.release()\n",
            "        cv2.destroyAllWindows()\n",
            "\n",
            "    @staticmethod\n",
            "    def parse_opt() -> argparse.Namespace:\n",
            "        \"\"\"\n",
            "        Parse command line arguments for the inference process.\n",
            "\n",
            "        Returns:\n",
            "            (argparse.Namespace): Parsed command line arguments.\n",
            "        \"\"\"\n",
            "        parser = argparse.ArgumentParser()\n",
            "        parser.add_argument(\"--weights\", type=str, default=\"yolo11n.pt\", help=\"initial weights path\")\n",
            "        parser.add_argument(\"--source\", type=str, required=True, help=\"video file path\")\n",
            "        parser.add_argument(\"--view-img\", action=\"store_true\", help=\"show results\")\n",
            "        parser.add_argument(\"--save-img\", action=\"store_true\", help=\"save results\")\n",
            "        parser.add_argument(\"--exist-ok\", action=\"store_true\", help=\"existing project/name ok, do not increment\")\n",
            "        parser.add_argument(\"--device\", default=\"\", help=\"cuda device, i.e. 0 or 0,1,2,3 or cpu\")\n",
            "        parser.add_argument(\"--hide-conf\", default=False, action=\"store_true\", help=\"display or hide confidences\")\n",
            "        parser.add_argument(\"--slice-width\", default=512, type=int, help=\"Slice width for inference\")\n",
            "        parser.add_argument(\"--slice-height\", default=512, type=int, help=\"Slice height for inference\")\n",
            "        return parser.parse_args()\n",
            "\n",
            "\n",
            "if __name__ == \"__main__\":\n",
            "    inference = SAHIInference()\n",
            "    inference.inference(**vars(inference.parse_opt()))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VTZkK9twdfBG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the original script\n",
        "with open('/content/ultralytics/examples/YOLOv8-SAHI-Inference-Video/yolov8_sahi.py', 'r') as f:\n",
        "    content = f.read()\n",
        "\n",
        "# Replace the problematic line\n",
        "content = content.replace(\n",
        "    'download_model_weights(yolo11_model_path)  # Download model if not present',\n",
        "    '# download_model_weights(yolo11_model_path)  # Commented out for YOLOv11 support'\n",
        ")\n",
        "\n",
        "# Write the modified script back\n",
        "with open('/content/ultralytics/examples/YOLOv8-SAHI-Inference-Video/yolov8_sahi.py', 'w') as f:\n",
        "    f.write(content)\n",
        "\n",
        "print(\"Script patched successfully!\")"
      ],
      "metadata": {
        "id": "xCYCvze0dck4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U ultralytics sahi opencv-python\n",
        "\n",
        "from sahi import AutoDetectionModel\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Download YOLOv11 first\n",
        "yolo_model = YOLO('yolo11s.pt')\n",
        "\n",
        "# Then use with SAHI\n",
        "detection_model = AutoDetectionModel.from_pretrained(\n",
        "    model_type='yolov8',\n",
        "    model_path='yolo11s.pt',\n",
        "    device='cuda:0'\n",
        ")\n",
        "\n",
        "#if you want to change model file\n",
        "!python yolov8_sahi.py --source \"/content/sahi.demo.video.mp4\" --weights \"yolo11s.pt\" --save-img"
      ],
      "metadata": {
        "id": "FBOo71vhuG5G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fc3813b-c001-4415-be78-acaa12bf826f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.11/dist-packages (8.3.144)\n",
            "Requirement already satisfied: sahi in /usr/local/lib/python3.11/dist-packages (0.11.23)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.10.0.84)\n",
            "Collecting opencv-python\n",
            "  Downloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.2.1)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.15.3)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.14)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from sahi) (8.2.0)\n",
            "Requirement already satisfied: fire in /usr/local/lib/python3.11/dist-packages (from sahi) (0.7.0)\n",
            "Requirement already satisfied: pybboxes==0.1.6 in /usr/local/lib/python3.11/dist-packages (from sahi) (0.1.6)\n",
            "Requirement already satisfied: shapely>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from sahi) (2.1.0)\n",
            "Requirement already satisfied: terminaltables in /usr/local/lib/python3.11/dist-packages (from sahi) (3.1.10)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.58.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.4.26)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from fire->sahi) (3.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/ultralytics/examples/YOLOv8-SAHI-Inference-Video/yolov8_sahi.py\", line 147, in <module>\n",
            "    inference.inference(**vars(inference.parse_opt()))\n",
            "  File \"/content/ultralytics/examples/YOLOv8-SAHI-Inference-Video/yolov8_sahi.py\", line 92, in inference\n",
            "    self.load_model(weights, device)\n",
            "  File \"/content/ultralytics/examples/YOLOv8-SAHI-Inference-Video/yolov8_sahi.py\", line 49, in load_model\n",
            "    download_model_weights(yolo11_model_path)  # Download model if not present\n",
            "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sahi/utils/ultralytics.py\", line 121, in download_model_weights\n",
            "    raise ValueError(f\"Unknown model: {model_name}\")\n",
            "ValueError: Unknown model: yolo11s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"center\">\n",
        "  <img width=\"1024\" src=\"https://github.com/ultralytics/docs/releases/download/0/yolo11n-vs-sahi-yolo11n.avif\" alt=\"SAHI Sliced Inference Overview\">\n",
        "</p>"
      ],
      "metadata": {
        "id": "bWskbLSKH2S5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Additional Arguments\n",
        "\n",
        "- `--source`: Defines the file path of the video on which inference will be performed.  \n",
        "- `--save-img`: Enables saving the detection results as a video file.  \n",
        "- `--weights`: Allows specifying a different YOLO11 model file (e.g., yolo11n.pt, yolov8s.pt, yolo11m.pt, yolo11l.pt, yolo11x.pt)."
      ],
      "metadata": {
        "id": "UTcl_tpK18XM"
      }
    }
  ]
}
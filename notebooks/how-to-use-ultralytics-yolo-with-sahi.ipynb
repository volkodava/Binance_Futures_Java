{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/volkodava/Binance_Futures_Java/blob/master/notebooks/how-to-use-ultralytics-yolo-with-sahi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mGmQbAO5pQb"
      },
      "source": [
        "### Setup\n",
        "\n",
        "pip install `ultralytics` and [dependencies](https://github.com/ultralytics/ultralytics/blob/main/pyproject.toml) and check software and hardware.\n",
        "\n",
        "[![PyPI - Version](https://img.shields.io/pypi/v/ultralytics?logo=pypi&logoColor=white)](https://pypi.org/project/ultralytics/) [![Downloads](https://static.pepy.tech/badge/ultralytics)](https://www.pepy.tech/projects/ultralytics) [![PyPI - Python Version](https://img.shields.io/pypi/pyversions/ultralytics?logo=python&logoColor=gold)](https://pypi.org/project/ultralytics/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbvMlHd_QwMG",
        "outputId": "ad3533f2-d8ee-4c5c-fe45-203fa8ce2d7e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install ultralytics sahi\n",
        "import ultralytics\n",
        "from ultralytics.utils.downloads import safe_download\n",
        "ultralytics.checks()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.144 ðŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Setup complete âœ… (2 CPUs, 12.7 GB RAM, 41.5/112.6 GB disk)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Clone Repository\n",
        "\n",
        "- Clone the `ultralytics` repository.\n",
        "- `%cd` to the examples section.\n",
        "- Move to `YOLOv8-SAHI-Inference-Video` folder."
      ],
      "metadata": {
        "id": "I7XY-vtnkPYf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone ultralytics repo\n",
        "!git clone https://github.com/ultralytics/ultralytics\n",
        "\n",
        "# cd to local directory\n",
        "%cd ultralytics/examples/YOLOv8-SAHI-Inference-Video"
      ],
      "metadata": {
        "id": "fNX-Ymha0HY6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5a69c8a-dee9-4e39-c9c9-fa96d89b2b32"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ultralytics'...\n",
            "remote: Enumerating objects: 60469, done.\u001b[K\n",
            "remote: Counting objects: 100% (53/53), done.\u001b[K\n",
            "remote: Compressing objects: 100% (32/32), done.\u001b[K\n",
            "remote: Total 60469 (delta 33), reused 32 (delta 21), pack-reused 60416 (from 2)\u001b[K\n",
            "Receiving objects: 100% (60469/60469), 32.80 MiB | 22.11 MiB/s, done.\n",
            "Resolving deltas: 100% (44943/44943), done.\n",
            "/content/ultralytics/examples/YOLOv8-SAHI-Inference-Video\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download the Sample Video\n",
        "\n",
        "- If you want to use your own video, you can skip this step."
      ],
      "metadata": {
        "id": "mWszyoifxOtR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "safe_download(f\"https://github.com/ultralytics/assets/releases/download/v0.0.0/sahi.demo.video.mp4\", dir=\"/content\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kkef3pklxVKP",
        "outputId": "560b2980-c3c6-45b1-e224-33e0b0ebdd77"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://ultralytics.com/assets/sahi.demo.video.mp4 to '/content/sahi.demo.video.mp4'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15.3M/15.3M [00:00<00:00, 105MB/s] \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PosixPath('/content/sahi.demo.video.mp4')"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inference using SAHI\n",
        "\n",
        "The output results will be stored in `ultralytics/ultralytics/examples/YOLOv8-SAHI-Inference-Video/`"
      ],
      "metadata": {
        "id": "yoP5eiVX1X37"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/ultralytics/examples/YOLOv8-SAHI-Inference-Video/yolov8_sahi.py', 'r') as f:\n",
        "    content = f.read()\n",
        "\n",
        "content = content.replace(\n",
        "    'download_model_weights(yolo11_model_path)  # Download model if not present',\n",
        "    '# download_model_weights(yolo11_model_path)  # Commented out for YOLOv11 support'\n",
        ")\n",
        "\n",
        "with open('/content/ultralytics/examples/YOLOv8-SAHI-Inference-Video/yolov8_sahi.py', 'w') as f:\n",
        "    f.write(content)\n",
        "\n",
        "print(\"Script patched successfully!\")"
      ],
      "metadata": {
        "id": "P9R8a6W_uEgP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "37af7d4d-7c49-4e8e-c7fe-2c112f6583db"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Script patched successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/ultralytics/examples/YOLOv8-SAHI-Inference-Video/yolov8_sahi.py --source \"/content/VisDrone2019-VID-test-challenge_sequences_uav0000354_00460_v.mp4\" --weights \"yolo11m.pt\" --save-img\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fvnaNgi8dZ_J",
        "outputId": "d04a6c98-96ca-4420-fb6e-cdacd63f4ea8"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.144 ðŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11m.pt to 'models/yolo11m.pt'...\n",
            "100% 38.8M/38.8M [00:00<00:00, 136MB/s]\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n",
            "Performing prediction on 6 slices.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/yolov8_sahi_video.py\n",
        "import argparse\n",
        "import cv2\n",
        "from sahi import AutoDetectionModel\n",
        "from sahi.predict import get_sliced_prediction\n",
        "from ultralytics.utils.files import increment_path\n",
        "from pathlib import Path\n",
        "\n",
        "class SAHIInference:\n",
        "    def __init__(self):\n",
        "        self.detection_model = None\n",
        "\n",
        "    def load_model(self, weights: str, device: str) -> None:\n",
        "        from ultralytics.utils.torch_utils import select_device\n",
        "        yolo11_model_path = f\"models/{weights}\"\n",
        "        self.detection_model = AutoDetectionModel.from_pretrained(\n",
        "            model_type=\"ultralytics\", model_path=yolo11_model_path, device=select_device(device)\n",
        "        )\n",
        "\n",
        "    def inference(\n",
        "        self,\n",
        "        weights: str = \"yolo11n.pt\",\n",
        "        source: str = \"test.mp4\",\n",
        "        view_img: bool = False,\n",
        "        save_img: bool = False,\n",
        "        exist_ok: bool = False,\n",
        "        device: str = \"\",\n",
        "        hide_conf: bool = False,\n",
        "        slice_width: int = 512,\n",
        "        slice_height: int = 512,\n",
        "    ) -> None:\n",
        "        cap = cv2.VideoCapture(source)\n",
        "        assert cap.isOpened(), \"Error reading video file\"\n",
        "\n",
        "        fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "        save_dir = increment_path(\"runs/detect/predict\", exist_ok)\n",
        "        save_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        video_path = None\n",
        "        if save_img:\n",
        "            video_path = save_dir / f\"{Path(source).stem}_output.mp4\"\n",
        "            fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "            out = cv2.VideoWriter(str(video_path), fourcc, fps, (width, height))\n",
        "            print(f\"Saving video to: {video_path.absolute()}\")\n",
        "\n",
        "        self.load_model(weights, device)\n",
        "\n",
        "        frame_count = 0\n",
        "        while cap.isOpened():\n",
        "            success, frame = cap.read()\n",
        "            if not success:\n",
        "                break\n",
        "\n",
        "            frame_count += 1\n",
        "            print(f\"Processing frame {frame_count}...\", end='\\r')\n",
        "\n",
        "            results = get_sliced_prediction(\n",
        "                frame[..., ::-1],\n",
        "                self.detection_model,\n",
        "                slice_height=slice_height,\n",
        "                slice_width=slice_width,\n",
        "            )\n",
        "\n",
        "            for obj in results.object_prediction_list:\n",
        "                x1 = int(obj.bbox.minx)\n",
        "                y1 = int(obj.bbox.miny)\n",
        "                x2 = int(obj.bbox.maxx)\n",
        "                y2 = int(obj.bbox.maxy)\n",
        "                score = obj.score.value\n",
        "                category = obj.category.name\n",
        "\n",
        "                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "                if not hide_conf:\n",
        "                    label = f'{category} {score:.2f}'\n",
        "                else:\n",
        "                    label = category\n",
        "                cv2.putText(frame, label, (x1, y1 - 10),\n",
        "                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "\n",
        "            if view_img:\n",
        "                cv2.imshow(\"Ultralytics YOLO Inference\", frame)\n",
        "\n",
        "            if save_img:\n",
        "                out.write(frame)\n",
        "\n",
        "            if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
        "                break\n",
        "\n",
        "        cap.release()\n",
        "        if save_img:\n",
        "            out.release()\n",
        "            print(f\"\\nâœ… Video saved to: {video_path.absolute()}\")\n",
        "        cv2.destroyAllWindows()\n",
        "\n",
        "    @staticmethod\n",
        "    def parse_opt() -> argparse.Namespace:\n",
        "        parser = argparse.ArgumentParser()\n",
        "        parser.add_argument(\"--weights\", type=str, default=\"yolo11n.pt\", help=\"initial weights path\")\n",
        "        parser.add_argument(\"--source\", type=str, required=True, help=\"video file path\")\n",
        "        parser.add_argument(\"--view-img\", action=\"store_true\", help=\"show results\")\n",
        "        parser.add_argument(\"--save-img\", action=\"store_true\", help=\"save results\")\n",
        "        parser.add_argument(\"--exist-ok\", action=\"store_true\", help=\"existing project/name ok, do not increment\")\n",
        "        parser.add_argument(\"--device\", default=\"\", help=\"cuda device, i.e. 0 or 0,1,2,3 or cpu\")\n",
        "        parser.add_argument(\"--hide-conf\", default=False, action=\"store_true\", help=\"display or hide confidences\")\n",
        "        parser.add_argument(\"--slice-width\", default=512, type=int, help=\"Slice width for inference\")\n",
        "        parser.add_argument(\"--slice-height\", default=512, type=int, help=\"Slice height for inference\")\n",
        "        return parser.parse_args()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    inference = SAHIInference()\n",
        "    inference.inference(**vars(inference.parse_opt()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pewDQAYphpFI",
        "outputId": "a18307ce-6c7e-423c-b5ba-b106806cb122"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/yolov8_sahi_video.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !python /content/yolov8_sahi_video.py --source \"/content/sahi.demo.video.mp4\" --weights \"yolo11x.pt\" --save-img\n",
        "!python /content/yolov8_sahi_video.py --source \"/content/VisDrone2019-SOT-test-challenge_part1_VisDrone2019-SOT-test-challenge_sequences_uav0000386_00001_s\" --weights \"yolo11m.pt\" --save-img"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_C--T2HiOzD",
        "outputId": "b2bd8079-bab7-4ece-9252-baf56f33e399"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/content/yolov8_sahi_video.py\", line 113, in <module>\n",
            "    inference.inference(**vars(inference.parse_opt()))\n",
            "  File \"/content/yolov8_sahi_video.py\", line 32, in inference\n",
            "    assert cap.isOpened(), \"Error reading video file\"\n",
            "           ^^^^^^^^^^^^^^\n",
            "AssertionError: Error reading video file\n"
          ]
        }
      ]
    }
  ]
}